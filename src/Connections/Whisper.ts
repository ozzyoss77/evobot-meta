import OpenAI from "openai";
import Queue from "queue-promise";
import tmp from "tmp";
import fs from "fs";
import Logger from "src/Utils/logger";
import 'dotenv/config';

const logger = new Logger();

logger.log(`üöÄ Whisper: Initializing OpenAI Whisper service`);

const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY,
});

logger.log(`‚úÖ Whisper: OpenAI client configured successfully`);

const queue = new Queue({
    concurrent: 1,
    interval: 100,
});

logger.log(`üîÑ Whisper: Processing queue initialized with concurrent: 1, interval: 100ms`);

async function processTranscription(buffer) {
    logger.log(`üéµ Whisper: Starting audio transcription process`);
    
    const bufferSize = (buffer.length / 1024).toFixed(2);
    logger.log(`üìä Whisper: Audio buffer size: ${bufferSize} KB`);
    
    const tempFile = tmp.fileSync({ postfix: '.ogg' });
    logger.log(`üìÅ Whisper: Created temporary file: ${tempFile.name}`);
    
    fs.writeFileSync(tempFile.name, buffer);
    logger.log(`üíæ Whisper: Audio buffer written to temporary file`);

    try {
        logger.log(`ü§ñ Whisper: Sending audio to OpenAI for transcription`);
        
        const transcription = await openai.audio.transcriptions.create({
            file: fs.createReadStream(tempFile.name),
            // model: "whisper-1"
            model: "gpt-4o-mini-transcribe"
        });

        const textLength = transcription.text.length;
        logger.log(`‚úÖ Whisper: Transcription completed successfully - ${textLength} characters`);
        logger.log(`üìù Whisper: Transcribed text: "${transcription.text.substring(0, 100)}${textLength > 100 ? '...' : ''}"`);

        tempFile.removeCallback();
        logger.log(`üóëÔ∏è Whisper: Temporary file cleaned up`);
        
        return transcription.text;
    } catch (error) {
        logger.error(`‚ùå Whisper: Error during transcription - ${error}`);
        tempFile.removeCallback();
        logger.log(`üóëÔ∏è Whisper: Temporary file cleaned up after error`);
        return 'La conversi√≥n fall√≥';
    }
}

function voiceToText(buffer) {
    logger.log(`üì• Whisper: Adding transcription request to processing queue`);
    
    return new Promise((resolve, reject) => {
        queue.enqueue(() => {
            logger.log(`‚öôÔ∏è Whisper: Processing transcription from queue`);
            return processTranscription(buffer)
                .then(result => {
                    logger.log(`‚úÖ Whisper: Queue processing completed successfully`);
                    resolve(result);
                })
                .catch(error => {
                    logger.error(`‚ùå Whisper: Queue processing failed - ${error}`);
                    reject(error);
                });
        });
    });
}

export {
    voiceToText
};